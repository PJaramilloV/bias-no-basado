{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier #kNN\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import RFE\n",
    "# from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "casearrest = pd.read_csv('../data/cleaned/casearrest_cl.csv', index_col=0)\n",
    "jailhistory = pd.read_csv('../data/cleaned/jailhistory_cl.csv', index_col=0)\n",
    "people = pd.read_csv('../data/cleaned/people_cl.csv', index_col=0)\n",
    "prisonhistory = pd.read_csv('../data/cleaned/prisonhistory_cl.csv', index_col=0)\n",
    "charge = pd.read_csv('../data/cleaned/charge_cl.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_best_features(df, target):\n",
    "    n_of_features = np.arange(1, df.shape[1]+1)\n",
    "    high_score = 0\n",
    "    nof = 0\n",
    "    score_list = []\n",
    "    for n in n_of_features:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df, target, test_size = 0.3, random_state = 0)\n",
    "        model = LinearRegression()\n",
    "        rfe = RFE(model, n_features_to_select=n)\n",
    "        X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "        X_test_rfe = rfe.transform(X_test)\n",
    "        model.fit(X_train_rfe, y_train)\n",
    "        score = model.score(X_test_rfe, y_test)\n",
    "        score_list.append(score)\n",
    "        if(score>high_score):\n",
    "            high_score = score\n",
    "            nof = n\n",
    "    return nof, high_score, score_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Caso `casearrest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casearrest:\n",
      "N of features: 3\n",
      "High score: 0.012440693217863563\n",
      "Score list: [0.008050461031538392, 0.012089443432227287, 0.012440693217863563]\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "casearrest_X = casearrest.drop(['decile_score'], axis='columns')\n",
    "casearrest_y = casearrest['decile_score']\n",
    "nof, high_score, score_list = get_best_features(casearrest_X, casearrest_y)\n",
    "print('Casearrest:')\n",
    "print('N of features:', nof)\n",
    "print('High score:', high_score)\n",
    "print('Score list:', score_list)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12,10))\n",
    "# cor = casearrest_X.corr()\n",
    "# sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "# plt.show()\n",
    "# son todas, asi que da igual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jailhistory:\n",
      "N of features: 3\n",
      "High score: 0.16073495854007736\n",
      "Score list: [0.01205922038852969, 0.037284843185304783, 0.16073495854007736]\n"
     ]
    }
   ],
   "source": [
    "jailhistory_X = jailhistory.drop(['decile_score'], axis='columns')\n",
    "jailhistory_y = jailhistory['decile_score']\n",
    "nof, high_score, score_list = get_best_features(jailhistory_X, jailhistory_y)\n",
    "print('jailhistory:')\n",
    "print('N of features:', nof)\n",
    "print('High score:', high_score)\n",
    "print('Score list:', score_list)\n",
    "\n",
    "# son todoas, asi que da igual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people:\n",
      "N of features: 20\n",
      "High score: 0.4482377264724221\n",
      "Score list: [-0.002203948720679083, 0.05160922465324713, 0.05484143558045085, 0.05655485210824196, 0.19831525083241386, 0.21585304056185683, 0.25488964016135207, 0.2955923588089835, 0.29608313107840334, 0.296107486768994, 0.30004315375235524, 0.3151062780841979, 0.315586353006027, 0.3230720009696194, 0.3227224393952839, 0.32242680988628114, 0.44768425608525864, 0.4476842560859339, 0.4480347641424699, 0.4482377264724221]\n"
     ]
    }
   ],
   "source": [
    "people_filter = people[people.columns[0:-9]].drop(columns=['age'])\n",
    "people_filter.head()\n",
    "df_race = pd.get_dummies(people_filter['race'], prefix='race', prefix_sep='_')\n",
    "df_sex = pd.get_dummies(people_filter['sex'], prefix='sex',\n",
    "                        prefix_sep='_', drop_first=True)\n",
    "\n",
    "people_filter = pd.concat([people_filter, df_race, df_sex], axis=1).drop('sex', axis=1).drop('race', axis=1)\n",
    "people_filter.head()\n",
    "people_X = people_filter.drop(['decile_score'], axis='columns')\n",
    "people_y = people_filter['decile_score']\n",
    "nof, high_score, score_list = get_best_features(people_X, people_y)\n",
    "print('people:')\n",
    "print('N of features:', nof)\n",
    "print('High score:', high_score)\n",
    "print('Score list:', score_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prisonhistory:\n",
      "N of features: 3\n",
      "High score: 0.0885879841366789\n",
      "Score list: [-0.006326693289959051, -0.008560941503100494, 0.0885879841366789]\n"
     ]
    }
   ],
   "source": [
    "prisonhistory_X = prisonhistory.drop(['decile_score'], axis='columns')\n",
    "prisonhistory_y = prisonhistory['decile_score']\n",
    "nof, high_score, score_list = get_best_features(prisonhistory_X, prisonhistory_y)\n",
    "print('prisonhistory:')\n",
    "print('N of features:', nof)\n",
    "print('High score:', high_score)\n",
    "print('Score list:', score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charge:\n",
      "N of features: 5\n",
      "High score: 0.05176000243535828\n",
      "Score list: [0.012744096442611985, 0.012840579721098533, 0.04289828847293886, 0.05066701750574043, 0.05176000243535828]\n"
     ]
    }
   ],
   "source": [
    "charge_X = charge.drop(['decile_score'], axis='columns')\n",
    "charge_y = charge['decile_score']\n",
    "nof, high_score, score_list = get_best_features(charge_X, charge_y)\n",
    "print('charge:')\n",
    "print('N of features:', nof)\n",
    "print('High score:', high_score)\n",
    "print('Score list:', score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ORIG Mejor combinación de parámetros:\n",
      "{'n_neighbors': 7, 'weights': 'distance'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.59      0.54       709\n",
      "           2       0.24      0.26      0.25       442\n",
      "           3       0.17      0.16      0.17       348\n",
      "           4       0.16      0.17      0.17       337\n",
      "           5       0.13      0.12      0.12       294\n",
      "           6       0.12      0.10      0.11       282\n",
      "           7       0.12      0.11      0.11       259\n",
      "           8       0.10      0.09      0.09       227\n",
      "           9       0.14      0.12      0.13       228\n",
      "          10       0.15      0.13      0.14       173\n",
      "\n",
      "    accuracy                           0.24      3299\n",
      "   macro avg       0.18      0.18      0.18      3299\n",
      "weighted avg       0.23      0.24      0.24      3299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parámetros a utilizar en GridSearch\n",
    "tuned_parameters = {'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                    'weights': ['uniform','distance']}\n",
    "score = 'f1'\n",
    "\n",
    "###separamos valores\n",
    "data_train, data_test, y_train, y_test = train_test_split(people_filter, people_filter['decile_score'], test_size=.30,\n",
    "                                                    random_state=15, stratify=people_filter['decile_score'])\n",
    "\n",
    "\n",
    "### dejamos los datos para trabajar\n",
    "y_test = data_test.decile_score\n",
    "X_test = data_test.drop(columns=['decile_score'])\n",
    "y_orig = data_train.decile_score\n",
    "X_orig = data_train.drop(columns=['decile_score'])\n",
    "\n",
    "\n",
    "### modelo del original\n",
    "clf_org = GridSearchCV(KNeighborsClassifier(),\n",
    "                       param_grid=tuned_parameters,\n",
    "                       cv=5,\n",
    "                       scoring=\"f1_macro\")\n",
    "print(\" ORIG Mejor combinación de parámetros:\")\n",
    "clf_org.fit(X_orig,y_orig)\n",
    "print(clf_org.best_params_)\n",
    "\n",
    "y_pred = clf_org.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tuned_parameters = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                    'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "                    'criterion': ['gini','entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ORIG Mejor combinación de parámetros:\n",
      "{'criterion': 'gini', 'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 12}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.81      0.65       709\n",
      "           2       0.25      0.35      0.29       442\n",
      "           3       0.20      0.12      0.15       348\n",
      "           4       0.19      0.20      0.19       337\n",
      "           5       0.15      0.14      0.14       294\n",
      "           6       0.13      0.09      0.11       282\n",
      "           7       0.16      0.11      0.13       259\n",
      "           8       0.18      0.13      0.15       227\n",
      "           9       0.20      0.12      0.15       228\n",
      "          10       0.25      0.16      0.20       173\n",
      "\n",
      "    accuracy                           0.31      3299\n",
      "   macro avg       0.23      0.22      0.22      3299\n",
      "weighted avg       0.27      0.31      0.28      3299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_org = GridSearchCV(DecisionTreeClassifier(),\n",
    "                       param_grid=tuned_parameters,\n",
    "                       cv=5,\n",
    "                       scoring=\"f1_macro\")\n",
    "print(\" ORIG Mejor combinación de parámetros:\")\n",
    "clf_org.fit(X_orig,y_orig)\n",
    "print(clf_org.best_params_)\n",
    "\n",
    "y_pred = clf_org.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_train = data_train.reset_index(drop=True)\n",
    "data_subsampled = data_train[data_train.decile_score == 10]\n",
    "for i in range(1,10):\n",
    "    idx = np.random.choice(data_train.loc[data_train['decile_score'] == i].index, size=404, replace=False)\n",
    "    data_subsampled = pd.concat([data_subsampled,  data_train.iloc[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SUB Mejor combinación de parámetros:\n",
      "{'n_neighbors': 9, 'weights': 'distance'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.41      0.48       709\n",
      "           2       0.20      0.20      0.20       442\n",
      "           3       0.14      0.15      0.15       348\n",
      "           4       0.14      0.15      0.15       337\n",
      "           5       0.12      0.12      0.12       294\n",
      "           6       0.12      0.13      0.13       282\n",
      "           7       0.11      0.11      0.11       259\n",
      "           8       0.09      0.11      0.10       227\n",
      "           9       0.14      0.14      0.14       228\n",
      "          10       0.15      0.21      0.18       173\n",
      "\n",
      "    accuracy                           0.21      3299\n",
      "   macro avg       0.18      0.17      0.17      3299\n",
      "weighted avg       0.23      0.21      0.22      3299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parámetros a utilizar en GridSearch\n",
    "tuned_parameters = {'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                    'weights': ['uniform','distance']}\n",
    "\n",
    "### dejamos los datos para trabajar\n",
    "y_test = data_test.decile_score\n",
    "X_test = data_test.drop(columns=['decile_score'])\n",
    "y_sub = data_subsampled.decile_score\n",
    "X_sub = data_subsampled.drop(columns=['decile_score'])\n",
    "\n",
    "\n",
    "### modelo del original\n",
    "clf_sub = GridSearchCV(KNeighborsClassifier(),\n",
    "                       param_grid=tuned_parameters,\n",
    "                       cv=5,\n",
    "                       scoring=\"f1_macro\")\n",
    "print(\" SUB Mejor combinación de parámetros:\")\n",
    "clf_sub.fit(X_sub,y_sub)\n",
    "print(clf_sub.best_params_)\n",
    "\n",
    "y_pred = clf_sub.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SUB Mejor combinación de parámetros:\n",
      "{'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 7}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.60      0.61       709\n",
      "           2       0.24      0.32      0.28       442\n",
      "           3       0.16      0.16      0.16       348\n",
      "           4       0.20      0.20      0.20       337\n",
      "           5       0.12      0.07      0.09       294\n",
      "           6       0.13      0.11      0.12       282\n",
      "           7       0.10      0.12      0.11       259\n",
      "           8       0.11      0.12      0.12       227\n",
      "           9       0.17      0.13      0.15       228\n",
      "          10       0.18      0.28      0.22       173\n",
      "\n",
      "    accuracy                           0.26      3299\n",
      "   macro avg       0.21      0.21      0.20      3299\n",
      "weighted avg       0.26      0.26      0.26      3299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                    'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "                    'criterion': ['gini','entropy']}\n",
    "\n",
    "### dejamos los datos para trabajar\n",
    "y_test = data_test.decile_score\n",
    "X_test = data_test.drop(columns=['decile_score'])\n",
    "y_sub = data_subsampled.decile_score\n",
    "X_sub = data_subsampled.drop(columns=['decile_score'])\n",
    "\n",
    "\n",
    "### modelo del original\n",
    "clf_sub = GridSearchCV(DecisionTreeClassifier(),\n",
    "                       param_grid=tuned_parameters,\n",
    "                       cv=5,\n",
    "                       scoring=\"f1_macro\")\n",
    "print(\" SUB Mejor combinación de parámetros:\")\n",
    "clf_sub.fit(X_sub,y_sub)\n",
    "print(clf_sub.best_params_)\n",
    "\n",
    "y_pred = clf_sub.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mineria')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "925f586314c742882e382f8f2b13597ffc50f489ccd6be3be7f934831046d87a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}